{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Statistics - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Typically, we don't know statistics about a population itself. The only way to know these for sure is to survey the entirety of the population, which is typically impractical. For example, to know the true salary mean of individuals in the United States, we would have to survey each and every individual.\n",
    "\n",
    "In lieu of being able to know the true underlying population statistics, we estimate them. Point estimates are estimates of population parameters based on sample data. For instance, if we wanted to know the average age of registered voters in the U.S., we could take a survey of registered voters and then use the average age of the respondents as a point estimate of the average age of the population as a whole. \n",
    "\n",
    "The average of a sample is known as the sample mean. Sampling distribution can be thought of as relative frequency distribution with a large number of samples. A relative frequency distribution tends to approach the sampling distribution as the number of samples increase.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Calculate and interpret sampling error\n",
    "* Explain how sample size is related to sampling error\n",
    "* Explain how the sampling error is related to population standard deviation\n",
    "\n",
    "## Background and Terminologies \n",
    "\n",
    "In order to learn the **population mean**, we don't measure the whole population. Instead, we take a random sample and use **sample mean, ( x_bar or $\\bar{x}$ )** to estimate the population mean **( mu or $\\mu$ )**. The sample mean is usually not exactly the same as the population mean and depends upon the values of samples chosen, however, the population mean remains fixed. While using the **sample mean** to estimate the population mean, we come across the **sampling error**, which directly relates to the **standard deviation** of a sampling statistic (e.g. mean values). This difference can be caused by many factors including poor survey design, biased sampling methods, and the randomness inherent to drawing a sample from a population.\n",
    "\n",
    "Let's learn about these concepts through an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Pumpkin Weights**\n",
    "\n",
    ">The population is the weight of six pumpkins (in pounds) displayed in a carnival \"Guess the Weight\" game booth. You are asked to guess the average weight of the six pumpkins by picking two pumpkins at a time randomly until all pumpkins have been used.\n",
    "\n",
    "| Pumpkin | Weight (in pounds) |\n",
    "|---------|--------------------|\n",
    "| A       |       19           |\n",
    "| B       |       14           |\n",
    "| C       |       15           |\n",
    "| D       |       9            |\n",
    "| E       |       10           |\n",
    "| F       |       17           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Let's calculate the population mean first, which we calculate as:\n",
    "\n",
    "**$\\large \\mu = \\frac{\\text{sum of all elements}}{N}$**, where N is population size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two lists, one with pumpkin names and one with the respective pumpkin weights. Combine the lists to create a pumpkin directory with the pumpkin names as keys and the pumpkin weights as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 19, 'B': 14, 'C': 15, 'D': 9, 'E': 10, 'F': 17}\n"
     ]
    }
   ],
   "source": [
    "# Create two lists with pumpkin names and weights\n",
    "\n",
    "pumpkin = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "weights = [19, 14, 15, 9, 10, 17]\n",
    "\n",
    "# Combine both lists to create a dictionary\n",
    "\n",
    "pumpkin_dict = dict(zip(pumpkin, weights))\n",
    "\n",
    "print (pumpkin_dict)\n",
    "\n",
    "#{'A': 19, 'B': 14, 'C': 15, 'D': 9, 'E': 10, 'F': 17}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to calculate the mean of the pumpkin population and also visualize the weight distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the population mean from pumpkin_dict\n",
    "\n",
    "def calculate_mu(x):\n",
    "\n",
    "    # Use the formula for mu given above\n",
    "    d = np.mean(list(x.values()))\n",
    "\n",
    "    return (d)   \n",
    "\n",
    "mu = calculate_mu(pumpkin_dict)\n",
    "mu\n",
    "\n",
    "# 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a pretty a straightforward exercise. Let's use the data we have so far to visualize the weights of individual pumpkins and mean weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar graph showing weights of pumpkins and highlight the mean weight\n",
    "\n",
    "plt.bar(pumpkin, weights)\n",
    "plt.axhline(calculate_mu(pumpkin_dict), color='red', linestyle='--', label='Mean')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see only one pumpkin has a weight which is equal to the mean weight (B:14). Let's try to simulate the random sampling process as stated below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Calculate the mean of samples\n",
    "\n",
    "From the `pumpkin_dict`, we can now obtain the sampling distributions of the sample mean for a given sample size. We'll do this while sampling *without* replacement (to reflect the idea that one can have two pumpkins at a given time, and will be taken out of population once used). \n",
    "\n",
    "Let's also try to make the code more flexible to allow sampling of any number of pumpkins from the population to study the effect of the sample size on the sample mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, first, we need to identify all the possible combinations that can be observed by choosing 2 pumpkins from the population, following the game rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'B'),\n",
       " ('A', 'C'),\n",
       " ('A', 'D'),\n",
       " ('A', 'E'),\n",
       " ('A', 'F'),\n",
       " ('B', 'C'),\n",
       " ('B', 'D'),\n",
       " ('B', 'E'),\n",
       " ('B', 'F'),\n",
       " ('C', 'D'),\n",
       " ('C', 'E'),\n",
       " ('C', 'F'),\n",
       " ('D', 'E'),\n",
       " ('D', 'F'),\n",
       " ('E', 'F')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify a sample size n \n",
    "n = 2 \n",
    "\n",
    "# Use itertools.combinations() to generate and print a list of combinations\n",
    "combs = list(itertools.combinations(pumpkin_dict.keys(), n))\n",
    "combs\n",
    "\n",
    "# Using 2 samples, we can see 15 possible combinations as below:\n",
    "# [('A', 'B'), ('A', 'C'), ('A', 'D'), ('A', 'E'), ('A', 'F'), ('B', 'C'), ('B', 'D'), \n",
    "#  ('B', 'E'), ('B', 'F'), ('C', 'D'), ('C', 'E'), ('C', 'F'), ('D', 'E'), ('D', 'F'), \n",
    "#  ('E', 'F')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can now generate any number of combinations from the population (try changing the value of `n` above). The next step in the process is to calculate the mean of all possible combinations and study whether these means differ from the population mean, and whether sample size has any effect on estimating the population mean. \n",
    "\n",
    "Let's write a function that would include the code for generating combinations as above and also for identifying the mean for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of population is: 14.0\n",
      "[(19, 14), (19, 15), (19, 9), (19, 10), (19, 17), (14, 15), (14, 9), (14, 10), (14, 17), (15, 9), (15, 10), (15, 17), (9, 10), (9, 17), (10, 17)] [16.5, 17.0, 14.0, 14.5, 18.0, 14.5, 11.5, 12.0, 15.5, 12.0, 12.5, 16.0, 9.5, 13.0, 13.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_means(sample_size, data):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes in population data as a dictionary along with a chosen sample size \n",
    "    to generate all possible combinations of given sample size. \n",
    "    The function calculates the mean of each sample and returns:\n",
    "    a) a list of all combinations ( as tuples ) \n",
    "    b) a list of means for all sample\n",
    "    \"\"\"\n",
    "\n",
    "    n = sample_size\n",
    "\n",
    "    # Calculate the mean of population\n",
    "    mu = calculate_mu(data)\n",
    "    print (\"Mean of population is:\", mu)\n",
    "\n",
    "    # Generate all possible combinations using given sample size\n",
    "    combs = list(itertools.combinations(pumpkin_dict.values(), sample_size))\n",
    "\n",
    "    # Calculate the mean weight (x_bar) for all the combinations (samples) using the given data\n",
    "    x_bar_list = []\n",
    "    for sample in combs:\n",
    "        x_bar= np.mean(sample)\n",
    "        \n",
    "    # Calculate sample mean for all combinations and append to x_bar_list\n",
    "        x_bar_list.append(x_bar)\n",
    "\n",
    "    return combs, x_bar_list\n",
    "\n",
    "n = 2 #Sample size\n",
    "\n",
    "combs, means = sample_means(n, pumpkin_dict)\n",
    "\n",
    "# Print the sample combinations with their means\n",
    "print(combs, means)\n",
    "\n",
    "# Using 2 samples, we can see 15 possible combinations as below:\n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "# ('A', 'B') 16.5\n",
    "# ('A', 'C') 17.0\n",
    "# ('A', 'D') 14.0\n",
    "# ('A', 'E') 14.5\n",
    "# ('A', 'F') 18.0\n",
    "# ('B', 'C') 14.5\n",
    "# ('B', 'D') 11.5\n",
    "# ('B', 'E') 12.0\n",
    "# ('B', 'F') 15.5\n",
    "# ('C', 'D') 12.0\n",
    "# ('C', 'E') 12.5\n",
    "# ('C', 'F') 16.0\n",
    "# ('D', 'E') 9.5\n",
    "# ('D', 'F') 13.0\n",
    "# ('E', 'F') 13.5\n",
    "# The mean of all sample means mu_x_hat is: 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, even though each sample may give you an answer involving some error, the expected value is right at the target: exactly the population mean. In other words: \n",
    ">If one does the experiment over and over again, the overall average of the sample mean is exactly the population mean.\n",
    "\n",
    "In the output above, we can see that some mean values i.e. 14.5, 12, are being repeated in the combinations. We can develop a frequency table to identify the probability of seeing a different mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16.5, 1),\n",
       " (17.0, 1),\n",
       " (14.0, 1),\n",
       " (14.5, 2),\n",
       " (18.0, 1),\n",
       " (11.5, 1),\n",
       " (12.0, 2),\n",
       " (15.5, 1),\n",
       " (12.5, 1),\n",
       " (16.0, 1),\n",
       " (9.5, 1),\n",
       " (13.0, 1),\n",
       " (13.5, 1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def calculate_probability(means):\n",
    "    '''\n",
    "    Input: a list of means (x_hats)\n",
    "    Output: a list of probablitity of each mean value\n",
    "    '''\n",
    "    #Calculate the frequency of each mean value\n",
    "    freq = Counter(means)\n",
    "    \n",
    "\n",
    "    prob = []\n",
    "\n",
    "    # Calculate and append frequency of each mean value in the prob list. \n",
    "    for mean_count in freq.items():\n",
    "        prob.append(mean_count)\n",
    "\n",
    "    return prob\n",
    "    \n",
    "probs = calculate_probability(means)\n",
    "\n",
    "# Print combinations with sample means and probability of each mean value\n",
    "probs\n",
    "\n",
    "# ('A', 'B') 16.5 1/15\n",
    "# ('A', 'C') 17.0 1/15\n",
    "# ('A', 'D') 14.0 1/15\n",
    "# ('A', 'E') 14.5 2/15\n",
    "# ('A', 'F') 18.0 1/15\n",
    "# ('B', 'C') 14.5 2/15\n",
    "# ('B', 'D') 11.5 1/15\n",
    "# ('B', 'E') 12.0 2/15\n",
    "# ('B', 'F') 15.5 1/15\n",
    "# ('C', 'D') 12.0 2/15\n",
    "# ('C', 'E') 12.5 1/15\n",
    "# ('C', 'F') 16.0 1/15\n",
    "# ('D', 'E') 9.5 1/15\n",
    "# ('D', 'F') 13.0 1/15\n",
    "# ('E', 'F') 13.5 1/15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the chance that the sample mean is exactly the population mean (i.e. 14) is only 1 in 15 (row 3), very small. It may also happen that the sample mean can never be the same value as the population mean. \n",
    "\n",
    "The difference between the sample mean and the population mean is known as the **Sampling Error**.  \n",
    "\n",
    ">When using the sample mean to estimate the population mean, some possible error will be involved since random sample means are also random.\n",
    "\n",
    "## Sample size and sampling error: \n",
    "\n",
    "Sample means cluster more closely around the population mean as the sample size increases. Thus, sampling error decreases as sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the above exercise while increasing the sample size from 2 to 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of population is: 14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(13.4, 1), (14.8, 1), (15.0, 1), (13.8, 1), (14.0, 1), (13.0, 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "# Use above functions to generate combinations as samples with means and calculate the probability of seeing\n",
    "# each mean value  with sample size = 5.\n",
    "combinations, xbars = sample_means(n, pumpkin_dict)\n",
    "\n",
    "calculate_probability(xbars)\n",
    "\n",
    "# Using 5 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "# 1 ('A', 'B', 'C', 'D', 'E') 13.4 1/6\n",
    "# 2 ('A', 'B', 'C', 'D', 'F') 14.8 1/6\n",
    "# 3 ('A', 'B', 'C', 'E', 'F') 15.0 1/6\n",
    "# 4 ('A', 'B', 'D', 'E', 'F') 13.8 1/6\n",
    "# 5 ('A', 'C', 'D', 'E', 'F') 14.0 1/6\n",
    "# 6 ('B', 'C', 'D', 'E', 'F') 13.0 1/6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that using the sample mean to estimate the population mean involves sampling error. Sample means do not fully agree with the population mean. The mean of sample means, however, is still 14. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fully appreciate the impact of sample size on estimating the population mean, let's try to visualize sample means and how the spread of values change when changing sample size. \n",
    "\n",
    "In a loop, run the above experiment with sample sizes ranging from 1 to 5 and measure and visualize the spread of values around the population mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of population is: 14.0\n",
      "[(19.0, 1), (14.0, 1), (15.0, 1), (9.0, 1), (10.0, 1), (17.0, 1)]\n",
      "Mean of population is: 14.0\n",
      "[(16.5, 1), (17.0, 1), (14.0, 1), (14.5, 2), (18.0, 1), (11.5, 1), (12.0, 2), (15.5, 1), (12.5, 1), (16.0, 1), (9.5, 1), (13.0, 1), (13.5, 1)]\n",
      "Mean of population is: 14.0\n",
      "[(16.0, 1), (14.0, 2), (14.333333333333334, 2), (16.666666666666668, 1), (14.666666666666666, 1), (17.0, 1), (12.666666666666666, 2), (15.0, 1), (15.333333333333334, 2), (13.0, 1), (11.0, 1), (13.333333333333334, 1), (13.666666666666666, 2), (11.333333333333334, 1), (12.0, 1)]\n",
      "Mean of population is: 14.0\n",
      "[(14.25, 1), (14.5, 1), (16.25, 1), (13.0, 1), (14.75, 1), (15.0, 2), (13.25, 1), (15.25, 1), (13.75, 2), (12.0, 1), (14.0, 1), (12.5, 1), (12.75, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Run a for loop to execute above code for sample size 1 to 5 and visualise the spread of sample \n",
    "# means\n",
    "for i in range (1,5):\n",
    "    combos, combomean = sample_means(i, pumpkin_dict)\n",
    "    print (calculate_probability(combomean))\n",
    "\n",
    "                \n",
    "# Using 1 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 2 samples with a population of size, we can see 15 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 3 samples with a population of size, we can see 20 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 4 samples with a population of size, we can see 15 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 5 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with increasing sample size, the **spread** of sample means is reduced and the sample mean values tend to come closer to the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the standard error\n",
    "\n",
    "### So what is standard error?\n",
    "\n",
    "The **_Standard Error (SE)_** is very similar to the standard deviation. Both are measures of spread. The higher the number, the more spread out your data is. To put it simply, the two terms are essentially equal — but there is one important difference. While the standard error uses statistics (sample data), standard deviations use parameters (population data). We achieve this by dividing the standard deviation by the square root of the sample size.\n",
    "\n",
    "The calculation for the standard error of the sample mean is:\n",
    "\n",
    "## $$ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\approx \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "Here, $\\sigma$ is the population standard deviation (which we will approximate with the sample standard deviation $s$) and $n$ is the sample size.\n",
    "\n",
    "Let's run the above block of code again and calculate the standard error according to the chosen sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of population is: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\core\\_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "yerr must be a scalar or a 1D or (2, n) array-like",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-929e3ed05fa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Visualize sample spread and standard error values for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#plt.bar(n, means, yerr=err_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'Sample size {n}'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2471\u001b[1;33m     return gca().bar(\n\u001b[0m\u001b[0;32m   2472\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2508\u001b[0m             \u001b[0merror_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_nolegend_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2510\u001b[1;33m             errorbar = self.errorbar(ex, ey,\n\u001b[0m\u001b[0;32m   2511\u001b[0m                                      \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2512\u001b[0m                                      fmt='none', **error_kw)\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36merrorbar\u001b[1;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[0;32m   3451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0myerr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3453\u001b[1;33m             \u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlolims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muplims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3454\u001b[0m             barcols.append(self.vlines(\n\u001b[0;32m   3455\u001b[0m                 *apply_mask([x, lower, upper], everymask), **eb_lines_style))\n",
      "\u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mextract_err\u001b[1;34m(name, err, data, lolims, uplims)\u001b[0m\n\u001b[0;32m   3401\u001b[0m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr\u001b[0m  \u001b[1;31m# Symmetric error: 1D iterable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3403\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   3404\u001b[0m                     f\"{name}err must be a scalar or a 1D or (2, n) array-like\")\n\u001b[0;32m   3405\u001b[0m             \u001b[1;31m# Using list comprehensions rather than arrays to preserve units.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: yerr must be a scalar or a 1D or (2, n) array-like"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create empty lists for storing sample means, combinations and standard error for each iteration\n",
    "means_list = []\n",
    "combs_list = []\n",
    "err_list = []\n",
    "# Create a for loop with changing sample sizes\n",
    "for n in range (1, len(pumpkin_dict)+1):\n",
    "    \n",
    "    # Calculate combinations, means as earlier, append to relevant lists\n",
    "    combinations, means = sample_means(n, pumpkin_dict)\n",
    "    means_list.append(means)\n",
    "    combs_list.append(combinations)\n",
    "    \n",
    "\n",
    "    # Calculate and append the standard error by dividing sample means with square root of sample size\n",
    "    for i in means:\n",
    "        #se = i / np.sqrt(n)\n",
    "        se = [np.std(combo, ddof=1) / np.sqrt(n) for combo in combinations]\n",
    "        err_list.append(se)\n",
    "    \n",
    "\n",
    "    # Visualize sample spread and standard error values for each sample\n",
    "        #plt.bar(n, means, yerr=err_list)\n",
    "        plt.bar([f'Sample size {n}'] * len(means), means, yerr=err_list, alpha=0.7, capsize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, even though each sample may give you an answer involving some error, the expected value is right at the target: exactly the population mean. In other words, if one does the experiment over and over again, the overall average of the sample mean is exactly the population mean. If the sample size is increased, the standard error is reduced. \n",
    "\n",
    "According to the **Central Limit Theorem**, for a large sample size, `x_hat` is approximately normally distributed, regardless of the distribution of the population one samples from.\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we saw how sampling statistics relate to population statistics. In order to estimate a population parameter (i.e. mean) with a high level of accuracy, We must reduce the spread or the sample error which is simply the standard deviation of the samples from the sample mean. The size of samples must be set carefully in order to avoid excessive values for standard error to gain a high level of confidence in our population estimates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
